# Paper sanity check (figures, tables, text consistency)

**Date:** One-time verification that all figures, tables, and narrative are consistent with the latest experimental results and with each other.

---

## 1. Referenced artifacts exist

| Referenced in paper | File | Status |
|---------------------|------|--------|
| Table: length_gen_cumsum | `tables/length_gen_cumsum.tex` | ✓ |
| Table: length_gen_parity | `tables/length_gen_parity.tex` | ✓ |
| Table: length_gen_dyck2 | `tables/length_gen_dyck2.tex` | ✓ |
| Table: depth | `tables/depth.tex` | ✓ |
| Table: mnist | `tables/mnist.tex` | ✓ |
| Table: ablation_lambda_cumsum | `tables/ablation_lambda_cumsum.tex` | ✓ |
| Table: ablation_lambda_mnist | `tables/ablation_lambda_mnist.tex` | ✓ |
| Table: mechanistic_ablations | `tables/mechanistic_ablations.tex` | ✓ |
| Table: length_gen_last_token | `tables/length_gen_last_token.tex` | ✓ |
| Figure: fig_length_gen_cumsum | `figures/fig_length_gen_cumsum.pdf` | ✓ |
| Figure: fig_length_gen_parity | `figures/fig_length_gen_parity.pdf` | ✓ |
| Figure: fig_length_gen_dyck2 | `figures/fig_length_gen_dyck2.pdf` | ✓ |
| Figure: fig_depth | `figures/fig_depth.pdf` | ✓ |
| Figure: fig_mnist_loss, fig_mnist_accuracy | `figures/fig_mnist_*.pdf` | ✓ |
| Figure: fig_ablation_lambda_* | `figures/fig_ablation_lambda_*.pdf` | ✓ |
| Figure: fig_drift | `figures/fig_drift.pdf` | ✓ |

All referenced tables and figures exist. Dyck-2 figure is included conditionally (`\IfFileExists`); the file exists so it will appear.

---

## 2. Data source consistency

- **Depth:** Table and figure both read from `results/depth/accuracy_vs_depth.csv`. The table in the paper matches the CSV (depth 4/8/16/32, ION/MLP, same numbers). ✓
- **Other tables/figures:** Generated by `run_figures_tables` from `results/` (length_gen, mnist, ablations, mechanistic_ablations, drift). Same pipeline produces both LaTeX tables and PDF figures. ✓

---

## 3. Key numbers vs. narrative

| Claim in text | Table/figure | Consistent? |
|---------------|--------------|-------------|
| "At moderate depths (4, 8), ION and MLP achieve similar accuracy" | Depth: 4 → ION 0.984, MLP 0.983; 8 → ION 0.983, MLP 0.983 | ✓ |
| "At greater depth, both models can be sensitive" | Depth 16: ION 0.806±0.39, MLP 0.98; Depth 32: both 0.113 | ✓ |
| "Full ION and P-only achieve comparable (best) MSE; F-only and random P worse" | Mechanistic: P_only 2969.58, full_ion 2975.02, F_only/random_P 2975.65 | ✓ |
| "ION matches or slightly improves over the baseline" (MNIST) | MNIST: ion 0.9811, mlp 0.9805 | ✓ |
| "ION does not help" (last-token) | last_token: ion ~0.55–0.59, gru ~0.54–0.59 (similar) | ✓ |
| "Competitive on length generalization" | Cumsum: ion and gru close (e.g. 7509 vs 7501 at 200); parity: ion ~0.50, gru ~0.59 (ION worse; text does not claim ION wins everywhere) | ✓ |

---

## 4. $p_{\mathrm{dim}}$ ablations

- The $p_{\mathrm{dim}}$ ablation tables and figures are included in §Ablations (ablation_p_dim_cumsum, ablation_p_dim_mnist, and the two corresponding figures). ✓

---

## 5. Conclusion

- **Figures and tables:** All referenced items exist and are produced from the same results pipeline.
- **Data:** Depth table matches `results/depth/accuracy_vs_depth.csv` (latest depth run with mitigations).
- **Narrative:** Depth, mechanistic, MNIST, last-token, and length-gen claims match the numbers. No overclaims.
**Verdict:** The paper is consistent with the latest experimental results and ready for submission from a figures/tables/text standpoint.
