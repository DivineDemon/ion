\section{Related Work}
\label{sec:related}

\paragraph{Length generalization and extrapolation.}
Neural sequence models often fail to generalize to sequence lengths beyond those seen during training~\cite{keysers2020measuring,anil2022exploring}, limiting their use in settings where test-time inputs are longer or variable. Prior work has studied this phenomenon in RNNs, Transformers, and state-space models~\cite{anil2022exploring}, with both empirical and theoretical characterizations of when length generalization occurs. ION addresses this by enforcing an explicit inductive consistency across time steps: a learned invariant $P(h_t)$ is propagated via a rule $F$, so that the representation obeys a recurrence that can in principle extend beyond the training horizon. Unlike methods that rely solely on architectural bias or data augmentation, ION adds a direct regularizer that encourages the hidden state to follow a predictable evolution along the sequence. The Long Range Arena (LRA)~\cite{tay2020long} benchmarks long-range reasoning; we evaluate ION on LRA ListOps (hierarchical expression classification) alongside synthetic length-generalization tasks.

\paragraph{Residual connections and depth.}
Residual networks~\cite{he2016deep} enable training of very deep networks by learning additive updates $h^{(l+1)} = h^{(l)} + f(h^{(l)})$, which improves gradient flow and often stabilizes optimization as depth increases. The residual formulation does not, however, impose a \emph{propagated quantity} that is conserved or evolved according to a fixed rule across layers. Universal ION complements this view: at each layer we define an invariant $p^{(l)} = P(h^{(l)})$ and encourage $P(h^{(l+1)}) \approx F(p^{(l)})$, so that a low-dimensional summary evolves consistently with depth. This can be combined with residual or non-residual backbones; the inductive loss is an additional constraint that may help maintain stable representations in deep feedforward nets.

\paragraph{Relation to predictive state, self-consistency, and temporal smoothness.}
Predictive state and temporal consistency methods often predict the next hidden state or apply fixed smoothing along time. ION differs by learning both a \emph{summary} map $P$ and an \emph{inductive rule} $F$ over that summary, and penalizing $\|P(h_{t+1}) - F(P(h_t), x_t)\|^2$; the constraint is thus on a low-dimensional propagated quantity, not on the full state. Self-consistency and auxiliary agreement losses typically enforce generic consistency (e.g., agreement between multiple samples or temporal smoothness of representations) without an explicit one-step recurrence $F$ applied to a learned $P$. ION's loss is explicitly inductive: it ties consecutive steps via a single learned rule, which supports extrapolation (Section~\ref{sec:method:theory}). Invariant learning in the symmetry sense assumes known groups or equivariances; ION does not assume any predefined symmetry---$P$ and $F$ are learned end-to-end with the task.

\paragraph{Invariants, equivariance, and neural ODEs.}
Equivariant and invariant networks~\cite{cohen2016group} build in symmetry by construction, so that representations transform in a prescribed way under group actions. Neural ODEs~\cite{chen2018neural} parameterize continuous-time dynamics and have been used to study depth as a continuous index. These lines of work do not typically learn an explicit \emph{inductive} rule that predicts the next invariant from the current one; the consistency is either hard-coded (equivariance) or implicit in the learned dynamics. ION instead learns both a summary map $P$ and a transition $F$ and penalizes deviation from $P(h_{t+1}) = F(P(h_t), x_t)$ (recurrent) or $P(h^{(l+1)}) = F(p^{(l)})$ (layers), yielding an explicit propagation law that is flexible yet constrained.

\paragraph{Neural algorithmic reasoning.}
Benchmarks such as CLRS~\cite{velickovic2022clrs} evaluate whether neural networks can learn and generalize algorithmic behavior, often including generalization to larger input sizes. Algorithmic tasks frequently have recursive or inductive structure (e.g., recurrence relations, dynamic programming), which aligns with the PMI view: a quantity (e.g., a state or partial result) should evolve according to a consistent rule. ION does not replace the reasoning architecture but adds an inductive auxiliary loss that may encourage the hidden state to follow such a rule, potentially improving generalization on algorithm-like sequence tasks.

\paragraph{Local learning and alternatives to backprop.}
Local learning methods train layers with local objectives or target propagation instead of end-to-end backpropagation~\cite{lee2015difference,nokland2019training}, offering benefits in memory, parallelism, or biological plausibility. ION does not remove backpropagation; the inductive loss $\mathcal{L}_{\mathrm{ind}}$ is differentiable and trained jointly with the task loss. In principle, the idea of enforcing a consistent propagation of a summary could be combined with local or target-propagation schemes in future work, e.g., by using $P$ and $F$ to define local targets along depth or time.
